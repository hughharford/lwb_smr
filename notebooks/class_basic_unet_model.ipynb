{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ec0335",
   "metadata": {},
   "outputs": [],
   "source": [
    "from class_PushMLFlow import PushMLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ac0400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model set up libraries \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Activation, ReLU\n",
    "from tensorflow.keras.layers import BatchNormalization, Conv2DTranspose, Concatenate\n",
    "from tensorflow.keras.models import Model, Sequential \n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import layers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b53aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelClass(PushMLFlow):\n",
    "    \"\"\"\n",
    "    Class inerhits from PushMLFlow and will push parameters and score when run and evaluate are called.\n",
    "    Inputs: X_train: [NumPy array] - trainning data\n",
    "            X_test: [NumPy array] - test data\n",
    "            y_train: [NumPy array] - trainning data\n",
    "            y_test: [NumPy array] - test data\n",
    "            loss: default='binary_crossentropy'\n",
    "            experiment_name: [str] - saved name of experiemnt \n",
    "            experiment_tags: [Dictionary]{'USER': '', 'RUN NAME': '', 'VERSION':'', 'DESCRIPTION':''} - Fill in relevant meta data\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    def __init__(self, X_train, X_test, y_train, y_test, loss='binary_crossentropy',experiment_name, experiment_tags):\n",
    "        super().__init__(experiment_name, experiment_tags)\n",
    "        self.loss=loss\n",
    "\n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "\n",
    "      \n",
    "    def convolution_operation(self, entered_input, filters=64):  \n",
    "            \n",
    "        # Taking first input and implementing the first conv block\n",
    "        conv1 = Conv2D(filters, kernel_size = (3,3), padding = \"same\")(entered_input)\n",
    "        batch_norm1 = BatchNormalization()(conv1)\n",
    "        act1 = ReLU()(batch_norm1)\n",
    "\n",
    "        # Taking first input and implementing the second conv block\n",
    "        conv2 = Conv2D(filters, kernel_size = (3,3), padding = \"same\")(act1)\n",
    "        batch_norm2 = BatchNormalization()(conv2)\n",
    "        act2 = ReLU()(batch_norm2)\n",
    "\n",
    "        return act2\n",
    "\n",
    "    def encoder(self, entered_input, filters=64):\n",
    "        # Collect the start and end of each sub-block for normal pass and skip connections\n",
    "        enc1 = self.convolution_operation(entered_input, filters)\n",
    "        MaxPool1 = MaxPooling2D(strides = (2,2))(enc1)\n",
    "        return enc1, MaxPool1\n",
    "\n",
    "    def decoder(self, entered_input, skip, filters=64):\n",
    "        # Upsampling and concatenating the essential features\n",
    "        Upsample = Conv2DTranspose(filters, (2, 2), strides=2, padding=\"same\")(entered_input)\n",
    "        Connect_Skip = Concatenate()([Upsample, skip])\n",
    "        out = self.convolution_operation(Connect_Skip, filters)\n",
    "        return out\n",
    "\n",
    "\n",
    "    def U_Net(self, Image_Size):\n",
    "        # Take the image size and shape\n",
    "        input1 = Input(Image_Size)\n",
    "\n",
    "        # Construct the encoder blocks\n",
    "        skip1, encoder_1 = self.encoder(input1, 64)\n",
    "        skip2, encoder_2 = self.encoder(encoder_1, 64*2)\n",
    "        skip3, encoder_3 = self.encoder(encoder_2, 64*4)\n",
    "        skip4, encoder_4 = self.encoder(encoder_3, 64*8)\n",
    "\n",
    "        # Preparing the next block\n",
    "        conv_block = self.convolution_operation(encoder_4, 64*16)\n",
    "\n",
    "        # Construct the decoder blocks\n",
    "        decoder_1 = self.decoder(conv_block, skip4, 64*8)\n",
    "        decoder_2 = self.decoder(decoder_1, skip3, 64*4)\n",
    "        decoder_3 = self.decoder(decoder_2, skip2, 64*2)\n",
    "        decoder_4 = self.decoder(decoder_3, skip1, 64)\n",
    "\n",
    "        out = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(decoder_4)\n",
    "\n",
    "        model = Model(input1, out)\n",
    "        return model\n",
    "\n",
    "    def set_model(self):\n",
    "        \n",
    "        # Instantiate Model\n",
    "        input_shape = self.X_train.shape[1:]\n",
    "        self.model = self.U_Net(input_shape)\n",
    "\n",
    "        # Compile Model\n",
    "        self.model.compile(loss=self.loss, \n",
    "                    optimizer='adam')\n",
    "\n",
    "    def run(self):\n",
    "\n",
    "        print(80*'-')\n",
    "        print('------MODEL RUNNING------')\n",
    "\n",
    "        # set model\n",
    "        self.set_model()\n",
    "\n",
    "        mc = ModelCheckpoint('oxford_segmentation.h5', save_best_only=True) # could put path here \n",
    "\n",
    "        self.model.fit(self.X_train, self.y_train, validation_split=0.3,\n",
    "                  batch_size=BATCH_SIZE, epochs=EPOCHS, callbacks=[mc])\n",
    "\n",
    "        self.mlflow_log_param('loss', self.loss)\n",
    "\n",
    "        print(80*'=')\n",
    "        print('------MODEL SUCCESFULLY------')\n",
    "\n",
    "\n",
    "    def evaluate(self):\n",
    "        print(80*'-')\n",
    "        print('------MODEL EVALUATING------')        \n",
    "        results = self.model.evaluate(self.X_test, self.y_test)\n",
    "        self.mlflow_log_metric('loss', results)\n",
    "        print(80*'=')\n",
    "        print('------MODEL EVALUATED------')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
