{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52d55dbf-f7a8-4232-bcf4-82569638ff1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# direct copy and paste from .py files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f260c50-8b65-4279-9362-e345f624d1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLFLOW_URI = \"https://mlflow.lewagon.ai/\"\n",
    "EXPERIMENT_NAME = \"UK LON lwb_smr SOLAR train 01\" # template\n",
    "EXPERIMENT_TAGS = {\n",
    "    'USER': 'hsth',\n",
    "    'RUN NAME': 'vertex2, operational, please',\n",
    "    'VERSION': 'M2_R02_15',\n",
    "    'DESCRIPTION': 'Model VGG16 UNet, 15 epochs, 72k images',\n",
    "    'LOSS': 'binary_crossentropy',\n",
    "    'METRICS': 'accuracy, binaryIoU, AUC'\n",
    "}\n",
    "\n",
    "\n",
    "UNET_INPUT_SHAPE = (224,224,3)\n",
    "TEST_BATCH_SIZE = 8\n",
    "BATCH_SIZE = TEST_BATCH_SIZE\n",
    "EPOCHS = 2\n",
    "LOSS='binary_crossentropy'\n",
    "\n",
    "# testing / otherwise\n",
    "SAMPLE_ONLY = 1\n",
    "\n",
    "# output filenames\n",
    "CHECKPOINT_NAME = 'test_220610_sample_CHECKER_checkpoint' #.h5 added below\n",
    "CHECKPOINT_PATH = '../raw_data/checkpoints/'\n",
    "\n",
    "MODEL_NAME = 'test_220610_sample_CHECKER_model_save'  #.h5 added below\n",
    "MODEL_PATH = '../raw_data/models/'\n",
    "\n",
    "# CRITICAL\n",
    "root_path = '../../raw_data'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2d074b-ef96-4cd9-a984-d8ae94a895e9",
   "metadata": {},
   "source": [
    "# TENSOR SLICE DATA LOADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6c942a20-9b3f-4303-9a83-4e141510352f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random #?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5a3542fc-4940-475b-9668-a567d66fdddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ef7e9acb-ef27-49fe-b037-93e9ae4e6990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>mask_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../../raw_data/train_mask_tiles_jpeg/austin19_...</td>\n",
       "      <td>../../raw_data/train_mask_tiles_jpeg/austin26_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../../raw_data/train_mask_tiles_jpeg/austin31_...</td>\n",
       "      <td>../../raw_data/train_mask_tiles_jpeg/austin33_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../../raw_data/train_mask_tiles_jpeg/chicago11...</td>\n",
       "      <td>../../raw_data/train_mask_tiles_jpeg/austin35_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../../raw_data/train_mask_tiles_jpeg/chicago11...</td>\n",
       "      <td>../../raw_data/train_mask_tiles_jpeg/chicago29...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../../raw_data/train_mask_tiles_jpeg/chicago16...</td>\n",
       "      <td>../../raw_data/train_mask_tiles_jpeg/chicago30...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_path  \\\n",
       "0  ../../raw_data/train_mask_tiles_jpeg/austin19_...   \n",
       "1  ../../raw_data/train_mask_tiles_jpeg/austin31_...   \n",
       "2  ../../raw_data/train_mask_tiles_jpeg/chicago11...   \n",
       "3  ../../raw_data/train_mask_tiles_jpeg/chicago11...   \n",
       "4  ../../raw_data/train_mask_tiles_jpeg/chicago16...   \n",
       "\n",
       "                                           mask_path  \n",
       "0  ../../raw_data/train_mask_tiles_jpeg/austin26_...  \n",
       "1  ../../raw_data/train_mask_tiles_jpeg/austin33_...  \n",
       "2  ../../raw_data/train_mask_tiles_jpeg/austin35_...  \n",
       "3  ../../raw_data/train_mask_tiles_jpeg/chicago29...  \n",
       "4  ../../raw_data/train_mask_tiles_jpeg/chicago30...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x_path = root_path + '/train_RGB_tiles_jpeg/'\n",
    "x_images = os.listdir(x_path)\n",
    "y_path = root_path + '/train_mask_tiles_jpeg/'\n",
    "y_masks = os.listdir(y_path)\n",
    "        \n",
    "folders = ['train_RGB_tiles_jpeg', 'train_mask_tiles_jpeg']\n",
    "folder_path = [f'{root_path}/{folder}' for folder in folders]\n",
    "folder_path\n",
    "\n",
    "train_images, train_mask = [], []\n",
    "if SAMPLE_ONLY == 1:\n",
    "    for i, filename in enumerate(os.listdir(folder_path[0])):\n",
    "        if i > (TEST_BATCH_SIZE * 2): break\n",
    "        train_images.append(f'{root_path}/train_mask_tiles_jpeg/{filename}')\n",
    "    for i, filename in enumerate(os.listdir(folder_path[1])):\n",
    "        if i > (TEST_BATCH_SIZE * 2): break\n",
    "        train_mask.append(f'{root_path}/train_mask_tiles_jpeg/{filename}')\n",
    "elif SAMPLE_ONLY == 0: \n",
    "    train_images =[f'{root_path}/train_RGB_tiles_jpeg/{filename}' for filename in os.listdir(folder_path[0])]\n",
    "    train_mask = [f'{root_path}/train_mask_tiles_jpeg/{filename}' for filename in os.listdir(folder_path[1])]\n",
    "\n",
    "    \n",
    "train_images.sort()\n",
    "train_mask.sort()\n",
    "\n",
    "\n",
    "train_df = pd.DataFrame()\n",
    "# train_df['file_path'] = train_images\n",
    "train_df['image_path'] = train_images\n",
    "train_df['mask_path'] = train_mask\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "237149c5-1be0-4939-a96e-b7709a28fef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def holdout(df, train_ratio=0.8, test_to_val_ratio=0.5, include_all=False):\n",
    "\n",
    "    img_paths = df[\"image_path\"].values\n",
    "    msk_paths = df[\"mask_path\"].values\n",
    "\n",
    "    df_mask = df.copy()\n",
    "\n",
    "    df_train, df_val = train_test_split(df_mask, train_size=train_ratio)\n",
    "    df_test, df_val = train_test_split(df_val, test_size=test_to_val_ratio)\n",
    "\n",
    "    ds_train = tf.data.Dataset.from_tensor_slices(\n",
    "         (df_train[\"image_path\"].values, df_train[\"mask_path\"].values)\n",
    "    )\n",
    "    ds_val = tf.data.Dataset.from_tensor_slices(\n",
    "        (df_val[\"image_path\"].values, df_val[\"mask_path\"].values)\n",
    "    )\n",
    "    ds_test = tf.data.Dataset.from_tensor_slices(\n",
    "        (df_test[\"image_path\"].values, df_test[\"mask_path\"].values)\n",
    "    )\n",
    "\n",
    "    return ds_train, ds_val, ds_test\n",
    "\n",
    "ds_train, ds_val, ds_test = holdout(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "052c664a-fcc9-4d0d-b32b-354c71c72f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_path(input_path, mask_path):\n",
    "    \"\"\"\n",
    "    Load images from files.\n",
    "    :input_path: the path to the satellite file\n",
    "    :mask_path: the path to the mask file\n",
    "    :return: The image and mask\n",
    "    .. note:: Works with jpg images \n",
    "              Only the first channel is kept for the mask\n",
    "    \"\"\"\n",
    "    \n",
    "    IMAGE_SQ_SIZE = 224\n",
    "\n",
    "    input_img = tf.io.read_file(input_path)   \n",
    "    input_img = tf.io.decode_jpeg(input_img, channels=3)\n",
    "    input_img =  tf.image.resize(input_img, [IMAGE_SQ_SIZE, IMAGE_SQ_SIZE])\n",
    "\n",
    "    mask_img = tf.io.read_file(mask_path)   \n",
    "    mask_img = tf.io.decode_jpeg(mask_img, channels=1)\n",
    "    mask_img =  tf.image.resize(mask_img, [IMAGE_SQ_SIZE, IMAGE_SQ_SIZE])\n",
    "\n",
    "   \n",
    "    return input_img, mask_img\n",
    "\n",
    "def normalize(image, mask):\n",
    "    # image = tf.cast(image, tf.float32) / 255.\n",
    "\n",
    "    return tf.math.divide(image, 255), tf.math.divide(mask, 255) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3020458d-5b34-4017-8849-2f05c9828ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "ds_train = ds_train.map(process_path) \\\n",
    ".map(normalize) \\\n",
    ".batch(batch_size=TEST_BATCH_SIZE) \\\n",
    ".prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0dd544eb-e58d-49aa-859c-b23d8a96bb5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 224, 224, 1), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0cb20e9e-2eac-455c-9eaa-ecdb2e682da3",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"/tmp/ipykernel_1095180/2956518407.py\", line 13, in process_path  *\n        input_img = tf.io.read_file(input_path)\n\n    TypeError: Input 'filename' of 'ReadFile' Op has type float32 that does not match expected type of string.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1095180/1093315005.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mds_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTEST_BATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mprefetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAUTOTUNE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2046\u001b[0m         warnings.warn(\"The `deterministic` argument has no effect unless the \"\n\u001b[1;32m   2047\u001b[0m                       \"`num_parallel_calls` argument is specified.\")\n\u001b[0;32m-> 2048\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mMapDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2049\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2050\u001b[0m       return ParallelMapDataset(\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m   5241\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_use_inter_op_parallelism\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_inter_op_parallelism\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5242\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preserve_cardinality\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5243\u001b[0;31m     self._map_func = structured_function.StructuredFunctionWrapper(\n\u001b[0m\u001b[1;32m   5244\u001b[0m         \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5245\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/data/ops/structured_function.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mfn_factory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace_tf_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefun_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m     \u001b[0;31m# There is no graph to add in eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0madd_to_graph\u001b[0m \u001b[0;34m&=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2565\u001b[0m          \u001b[0;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorSpec\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2566\u001b[0m     \"\"\"\n\u001b[0;32m-> 2567\u001b[0;31m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0m\u001b[1;32m   2568\u001b[0m         *args, **kwargs)\n\u001b[1;32m   2569\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2531\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2532\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2533\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2534\u001b[0m       \u001b[0mseen_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2535\u001b[0m       captured = object_identity.ObjectIdentitySet(\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2709\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache_key\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_placeholder_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2711\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2712\u001b[0m           self._function_cache.add(cache_key, cache_key_deletion_observer,\n\u001b[1;32m   2713\u001b[0m                                    graph_function)\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2625\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2626\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 2627\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   2628\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1139\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1141\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/data/ops/structured_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    246\u001b[0m           attributes=defun_kwargs)\n\u001b[1;32m    247\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/data/ops/structured_function.py\u001b[0m in \u001b[0;36mwrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    175\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_should_unpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0m_should_pack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    690\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/__autograph_generated_file_x4b5xq4.py\u001b[0m in \u001b[0;36mtf__process_path\u001b[0;34m(input_path, mask_path)\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefinedReturnValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0mIMAGE_SQ_SIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                 \u001b[0minput_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m                 \u001b[0minput_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_jpeg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0minput_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMAGE_SQ_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMAGE_SQ_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_in_allowlist_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Allowlisted %s: from cache'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    457\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/ops/io_ops.py\u001b[0m in \u001b[0;36mread_file\u001b[0;34m(filename, name)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0mA\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0mof\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m\"string\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfile\u001b[0m \u001b[0mcontents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m   \"\"\"\n\u001b[0;32m--> 133\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_io_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/ops/gen_io_ops.py\u001b[0m in \u001b[0;36mread_file\u001b[0;34m(filename, name)\u001b[0m\n\u001b[1;32m    569\u001b[0m       \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0m\u001b[1;32m    572\u001b[0m         \"ReadFile\", filename=filename, name=name)\n\u001b[1;32m    573\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    777\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m       _ExtractInputsAndAttrs(op_type_name, op_def, allowed_list_attr_map,\n\u001b[0m\u001b[1;32m    780\u001b[0m                              \u001b[0mkeywords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_type_attr_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m                              input_types)\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_ExtractInputsAndAttrs\u001b[0;34m(op_type_name, op_def, allowed_list_attr_map, keywords, default_type_attr_map, attrs, inputs, input_types)\u001b[0m\n\u001b[1;32m    577\u001b[0m                   (input_name, op_type_name, observed))\n\u001b[1;32m    578\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtypes_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDT_INVALID\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m           raise TypeError(f\"{prefix} expected type of \"\n\u001b[0m\u001b[1;32m    580\u001b[0m                           f\"{dtypes.as_dtype(input_arg.type).name}.\")\n\u001b[1;32m    581\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/tmp/ipykernel_1095180/2956518407.py\", line 13, in process_path  *\n        input_img = tf.io.read_file(input_path)\n\n    TypeError: Input 'filename' of 'ReadFile' Op has type float32 that does not match expected type of string.\n"
     ]
    }
   ],
   "source": [
    "ds_val = ds_val.map(process_path) \\\n",
    ".map(normalize) \\\n",
    ".batch(batch_size=TEST_BATCH_SIZE) \\\n",
    ".prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7d74db3d-59f2-48b4-b631-0a60de6bfa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7925488-670a-4d53-97e9-fde6788e6c0d",
   "metadata": {},
   "source": [
    "# model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1ab6d800-39ea-4458-bdcb-abff179bd1ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Activation, ReLU\n",
    "from tensorflow.keras.layers import BatchNormalization, Conv2DTranspose, Concatenate\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class SMR_Model():\n",
    "    ''' creating our first lwb_smr models '''\n",
    "\n",
    "    def __init__(self, input_shape):\n",
    "        self.input_shape = input_shape\n",
    "\n",
    "    def get_latest_model(self):\n",
    "        model = self.build_vgg16_unet(self.input_shape)\n",
    "        model = self.compile_model(model)\n",
    "\n",
    "        return model\n",
    "\n",
    "    def convolution_block(self, inputs, num_filters):\n",
    "        ''' simple UNET convolution block with BatchNormalisation '''\n",
    "\n",
    "        # convolution layer 1 of the block\n",
    "        x = Conv2D(num_filters, (3,3), padding='same')(inputs)  # padding='same' to avoid cut-down with conv\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        # convolution layer 2 of the block\n",
    "        x = Conv2D(num_filters, (3,3), padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        # max pooling not used here as just the bridge\n",
    "\n",
    "        return x\n",
    "\n",
    "    def decoder_block(self, inputs, skip_tensor, num_filters):\n",
    "        ''' decoder block for UNET '''\n",
    "        # adds in the skips with concatenate\n",
    "        x = Conv2DTranspose(num_filters, (2,2), strides=2, padding='same')(inputs) # stride important here to up-sample\n",
    "        x = Concatenate()([x, skip_tensor])     # bringing in skip layer\n",
    "        x = self.convolution_block(x, num_filters)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def build_vgg16_unet(self, input_shape):\n",
    "        ''' build vgg-16 '''\n",
    "\n",
    "        inputs = Input(input_shape)\n",
    "\n",
    "        # see actual VGG-16 here: https://github.com/keras-team/keras/blob/v2.9.0/keras/applications/vgg16.py#L43-L227\n",
    "        vgg16 = VGG16(include_top=False, weights='imagenet', input_tensor=inputs)\n",
    "        # vgg16.summary()\n",
    "        vgg16.trainable = False\n",
    "\n",
    "        ''' Encoder - skip layers '''\n",
    "        skip1 = vgg16.get_layer('block1_conv2').output #  256 x 256, 64 filters in vgg16\n",
    "        skip2 = vgg16.get_layer('block2_conv2').output #  128 x 128, 128 filters in vgg16\n",
    "        skip3 = vgg16.get_layer('block3_conv3').output #   64 x 64, 256 filters in vgg16\n",
    "        skip4 = vgg16.get_layer('block4_conv3').output #   32 x 32, 512 filters in vgg16\n",
    "        # display('skip4: ' + str(skip4.shape))\n",
    "\n",
    "        # only need to specify the skip layers, as VGG16 is an Encoder\n",
    "        # Therefore, VGG16 comes built with MaxPool2d, so we don't specify\n",
    "\n",
    "        ''' Bridge '''\n",
    "        bridge = vgg16.get_layer('block5_conv3').output # 16 x 16, with 512 filters in vgg16\n",
    "        # display('bridge: ' + str(bridge.shape))\n",
    "\n",
    "\n",
    "        ''' Decoder '''\n",
    "        d1 = self.decoder_block(bridge, skip4, 512) #  512 filters, as per the bridge\n",
    "        d2 = self.decoder_block(d1, skip3, 256) #  256 filters\n",
    "        d3 = self.decoder_block(d2, skip2, 128) #  128 filters\n",
    "        d4 = self.decoder_block(d3, skip1, 64)  #   64 filters\n",
    "\n",
    "        ''' Output '''\n",
    "        outputs = Conv2D(1, (1,1), padding='same', activation='sigmoid')(d4)\n",
    "\n",
    "        model = Model(inputs, outputs, name='first_VGG16_UNET')\n",
    "\n",
    "        return model\n",
    "\n",
    "    def compile_model(self, m):\n",
    "        ''' with accuracy, binaryIoU, AuC '''\n",
    "        # binaryIoU metric\n",
    "        threshold = 0.5\n",
    "        binaryIoU = tf.keras.metrics.BinaryIoU(target_class_ids=[1], threshold=threshold)\n",
    "        AuC = tf.keras.metrics.AUC()\n",
    "\n",
    "        # Compile Model\n",
    "        m.compile(\n",
    "                    loss=LOSS,\n",
    "                    optimizer='adam',\n",
    "                    metrics=['accuracy', binaryIoU, AuC]\n",
    "                    )\n",
    "        return m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e02df14-1730-4a67-84d9-6df7918d7cfe",
   "metadata": {
    "tags": []
   },
   "source": [
    "# utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c9f96beb-091b-4ebf-815a-26b02d7ea818",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# mlflow\n",
    "#\n",
    "# and others...\n",
    "\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "from memoized_property import memoized_property\n",
    "\n",
    "MLFLOW_URI = \"https://mlflow.lewagon.ai/\"\n",
    "\n",
    "class PushMLFlow():\n",
    "    '''\n",
    "        MLFLOW_URI = \"https://mlflow.lewagon.ai/\"\n",
    "        EXPERIMENT_NAME = \"[UK] [LONDON] [SOLAR_ROOF] TEST RUN\" # template\n",
    "        EXPERIMENT_TAGS = {\n",
    "            'USER': 'test_user',\n",
    "            'RUN NAME': 'test runs',\n",
    "            'VERSION': '1.0.1',\n",
    "            'DESCRIPTION': 'testing MLFlow Pipeline. Model - basic U-Net structure, 2 epochs, 15 images'\n",
    "        }\n",
    "    '''\n",
    "\n",
    "    def __init__(self, experiment_name, experiment_tags):\n",
    "        self.experiment_name = experiment_name\n",
    "        self.experiment_tag = experiment_tags\n",
    "\n",
    "        pass\n",
    "    @memoized_property\n",
    "    def mlflow_client(self):\n",
    "        mlflow.set_tracking_uri(MLFLOW_URI)\n",
    "        return MlflowClient()\n",
    "\n",
    "    @memoized_property\n",
    "    def mlflow_experiment_id(self):\n",
    "        try:\n",
    "            return self.mlflow_client.create_experiment(self.experiment_name)\n",
    "        except BaseException:\n",
    "            return self.mlflow_client.get_experiment_by_name(self.experiment_name).experiment_id\n",
    "\n",
    "    @memoized_property\n",
    "    def mlflow_run(self):\n",
    "        return self.mlflow_client.create_run(self.mlflow_experiment_id, tags=self.experiment_tag)\n",
    "\n",
    "    def mlflow_log_param(self, key, value):\n",
    "        self.mlflow_client.log_param(self.mlflow_run.info.run_id, key, value)\n",
    "\n",
    "    def mlflow_log_metric(self, key, value):\n",
    "        self.mlflow_client.log_metric(self.mlflow_run.info.run_id, key, value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3d60ba85-ce10-431b-b21a-dd584f8a4a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6352a612-b695-41e5-83a0-828ecdd13dc8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "------SETTING FOR DATA RUN------\n",
      "--------------------------------------------------------------------------------\n",
      "------MODEL RUNNING------\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-10 11:42:13.794296: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at whole_file_read_ops.cc:114 : NOT_FOUND: ../../raw_data/train_mask_tiles_jpeg/vienna32_x08_y08.jpeg; No such file or directory\n",
      "2022-06-10 11:42:13.794870: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at whole_file_read_ops.cc:114 : NOT_FOUND: ../../raw_data/train_mask_tiles_jpeg/austin31_x01_y12.jpeg; No such file or directory\n",
      "2022-06-10 11:42:13.794925: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at whole_file_read_ops.cc:114 : NOT_FOUND: ../../raw_data/train_mask_tiles_jpeg/chicago11_x01_y11.jpeg; No such file or directory\n",
      "2022-06-10 11:42:13.794960: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at whole_file_read_ops.cc:114 : NOT_FOUND: ../../raw_data/train_mask_tiles_jpeg/tyrol-w3_x14_y11.jpeg; No such file or directory\n",
      "2022-06-10 11:42:13.795013: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at whole_file_read_ops.cc:114 : NOT_FOUND: ../../raw_data/train_mask_tiles_jpeg/kitsap3_x00_y02.jpeg; No such file or directory\n",
      "2022-06-10 11:42:13.795471: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at whole_file_read_ops.cc:114 : NOT_FOUND: ../../raw_data/train_mask_tiles_jpeg/tyrol-w31_x14_y10.jpeg; No such file or directory\n",
      "2022-06-10 11:42:13.795524: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at whole_file_read_ops.cc:114 : NOT_FOUND: ../../raw_data/train_mask_tiles_jpeg/austin19_x17_y18.jpeg; No such file or directory\n",
      "2022-06-10 11:42:13.795689: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at whole_file_read_ops.cc:114 : NOT_FOUND: ../../raw_data/train_mask_tiles_jpeg/chicago35_x14_y18.jpeg; No such file or directory\n",
      "2022-06-10 11:42:13.795972: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at whole_file_read_ops.cc:114 : NOT_FOUND: ../../raw_data/train_mask_tiles_jpeg/vienna5_x01_y12.jpeg; No such file or directory\n",
      "2022-06-10 11:42:13.795995: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at whole_file_read_ops.cc:114 : NOT_FOUND: ../../raw_data/train_mask_tiles_jpeg/vienna32_x02_y06.jpeg; No such file or directory\n",
      "2022-06-10 11:42:13.796107: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at whole_file_read_ops.cc:114 : NOT_FOUND: ../../raw_data/train_mask_tiles_jpeg/tyrol-w17_x07_y19.jpeg; No such file or directory\n",
      "2022-06-10 11:42:13.796265: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at whole_file_read_ops.cc:114 : NOT_FOUND: ../../raw_data/train_mask_tiles_jpeg/kitsap13_x07_y11.jpeg; No such file or directory\n",
      "2022-06-10 11:42:13.796740: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at whole_file_read_ops.cc:114 : NOT_FOUND: ../../raw_data/train_mask_tiles_jpeg/vienna6_x10_y00.jpeg; No such file or directory\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Graph execution error:\n\n../../raw_data/train_mask_tiles_jpeg/vienna32_x08_y08.jpeg; No such file or directory\n\t [[{{node ReadFile}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_14129]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1095180/2309857522.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_1095180/2309857522.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mmc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{CHECKPOINT_PATH}/{CHECKPOINT_NAME}.h5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# could put path here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         self.model.fit(\n\u001b[0m\u001b[1;32m     56\u001b[0m             \u001b[0mds_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Graph execution error:\n\n../../raw_data/train_mask_tiles_jpeg/vienna32_x08_y08.jpeg; No such file or directory\n\t [[{{node ReadFile}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_14129]"
     ]
    }
   ],
   "source": [
    "# THIS NEEDS TO BE WRITTEN OUT PROPERLY!\n",
    "# ESPECIALLY THE FIRST BIT THAT SHOULD BE IN DATA.py as Josh has been writing\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# from lwb_smr.CustomDataLoader import CustomDataLoader\n",
    "# from lwb_smr.model import SMR_Model\n",
    "# from lwb_smr.utils import PushMLFlow\n",
    "\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# from tensorflow.keras.metrics import AUC, IoU\n",
    "\n",
    "\n",
    "class Trainer():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def set_model(self, loss=LOSS):\n",
    "        self.loss = loss\n",
    "        # Instantiate Model\n",
    "        # our_input_shape = (224,224,3)\n",
    "\n",
    "        getVGG16 = SMR_Model(UNET_INPUT_SHAPE)\n",
    "        self.model = getVGG16.get_latest_model()\n",
    "        # see compile in SMR_Model\n",
    "\n",
    "    def start_mlflow(self):\n",
    "        p = PushMLFlow(EXPERIMENT_NAME, EXPERIMENT_TAGS)\n",
    "        return p.mlflow_run\n",
    "\n",
    "    def run(self):\n",
    "\n",
    "        print(80*'-')\n",
    "        print('------SETTING FOR DATA RUN------')\n",
    "\n",
    "        ### \n",
    "        ##\n",
    "        #\n",
    "        # customdata = self.just_get_the_data_loaded()\n",
    "\n",
    "        print(80*'-')\n",
    "        print('------MODEL RUNNING------')\n",
    "\n",
    "        # set mflow\n",
    "        self.MFLOW = self.start_mlflow()\n",
    "\n",
    "        # set model\n",
    "        self.set_model()\n",
    "\n",
    "        mc = ModelCheckpoint(f'{CHECKPOINT_PATH}/{CHECKPOINT_NAME}.h5', save_best_only=True) # could put path here\n",
    "        es = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "        self.model.fit(\n",
    "            ds_train,\n",
    "            validation_data=ds_val,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            epochs=EPOCHS,\n",
    "            callbacks=[mc, es]\n",
    "            )\n",
    "        \n",
    "        ## This worked...\n",
    "        # self.model.fit(\n",
    "        #     customdata,\n",
    "        #     # validation_split=0.3,\n",
    "        #     batch_size=BATCH_SIZE,\n",
    "        #     epochs=EPOCHS,\n",
    "        #     callbacks=[mc, es]\n",
    "        #     )\n",
    "    \n",
    "\n",
    "        model_path_and_filename = f'{MODEL_PATH}/{MODEL_NAME}/.h5'\n",
    "        # '../models/220610_sampleCHECKER_UNET_input_shape_224x224x3.h5'\n",
    "        self.model.save(model_path_and_filename)\n",
    "        # HERE HERE HERE HERE\n",
    "        # line above missing: self.\n",
    "        \n",
    "        self.MFLOW.mlflow_log_param('loss', self.loss)\n",
    "\n",
    "        print(80*'=')\n",
    "        print('------MODEL RUN SUCCESFULLY COMPLETED------')\n",
    "\n",
    "        self.evaluate()\n",
    "\n",
    "    def evaluate(self):\n",
    "        print(80*'-')\n",
    "        print('------MODEL EVALUATING------')\n",
    "        results = self.model.evaluate(self.X_test, self.y_test)\n",
    "        self.MFLOW.mlflow_log_metric('loss', results)\n",
    "        print(80*'=')\n",
    "        print('------MODEL EVALUATED------')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    pass\n",
    "    t = Trainer()\n",
    "    t.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633bd30b-3127-4f24-8ade-052e58ad8051",
   "metadata": {},
   "outputs": [],
   "source": [
    "########\n",
    "####\n",
    "###\n",
    "#\n",
    "#        binaryIoU goes up with tensorslices, and not with customdata\n",
    "#\n",
    "##\n",
    "###\n",
    "####\n",
    "########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6fd1ff-e898-4563-8f26-d622e1b26976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @@@@@@@@@@@@@ but will it go to 2+ epochs??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c581b3-33df-4d7e-af3d-2de9012d61cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YES, finally...!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3a423a-412f-4166-8789-9b4aa0761e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUT!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02eb5d45-0f51-4598-b4f4-390f4539cd10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84369401-29d3-4b40-9245-af8c21efd28c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dc5f6f-d110-4971-8a08-841db1c4071a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbb928b-1177-4ea6-aebf-4676e6c2cdda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cecde7a-e023-4666-b2dc-2a8e5255821a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fa7715-82c4-4e23-b02d-388a012092b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2d33c0-2c04-49e2-b414-75fd18cbff8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38aafbba-1b78-4f2a-a4cb-2721801edefb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180deaca-ef12-49ea-8a37-97a142131fe2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ebe7a2-4a12-4f67-95d3-239e29558bb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40599acb-6800-42b4-bbe5-2173708c9177",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab969ba-2ced-4923-adce-bc2b1d67f355",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m93",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m93"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
