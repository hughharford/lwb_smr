{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# IMPORTS"
      ],
      "metadata": {
        "id": "hj9EhoQVDpxd"
      },
      "id": "hj9EhoQVDpxd"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "096f7da1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "096f7da1",
        "outputId": "c8d67cfa-5c96-4c9f-9609-3e539b060639"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: mlflow in /usr/local/lib/python3.7/dist-packages (1.26.1)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from mlflow) (3.17.3)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from mlflow) (2022.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mlflow) (21.3)\n",
            "Requirement already satisfied: docker>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from mlflow) (5.0.3)\n",
            "Requirement already satisfied: importlib-metadata!=4.7.0,>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from mlflow) (4.11.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.4.1)\n",
            "Requirement already satisfied: Flask in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.21.6)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.4.36)\n",
            "Requirement already satisfied: prometheus-flask-exporter in /usr/local/lib/python3.7/dist-packages (from mlflow) (0.20.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from mlflow) (6.0)\n",
            "Requirement already satisfied: requests>=2.17.3 in /usr/local/lib/python3.7/dist-packages (from mlflow) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.3.5)\n",
            "Requirement already satisfied: gitpython>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from mlflow) (3.1.27)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from mlflow) (7.1.2)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from mlflow) (0.4)\n",
            "Requirement already satisfied: gunicorn in /usr/local/lib/python3.7/dist-packages (from mlflow) (20.1.0)\n",
            "Requirement already satisfied: databricks-cli>=0.8.7 in /usr/local/lib/python3.7/dist-packages (from mlflow) (0.16.6)\n",
            "Requirement already satisfied: querystring-parser in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.2.4)\n",
            "Requirement already satisfied: sqlparse>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from mlflow) (0.4.2)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.3.0)\n",
            "Requirement already satisfied: alembic in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.8.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from databricks-cli>=0.8.7->mlflow) (1.15.0)\n",
            "Requirement already satisfied: oauthlib>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from databricks-cli>=0.8.7->mlflow) (3.2.0)\n",
            "Requirement already satisfied: pyjwt>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from databricks-cli>=0.8.7->mlflow) (2.4.0)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from databricks-cli>=0.8.7->mlflow) (0.8.9)\n",
            "Requirement already satisfied: websocket-client>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from docker>=4.0.0->mlflow) (1.3.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from gitpython>=2.1.0->mlflow) (4.0.9)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from gitpython>=2.1.0->mlflow) (4.2.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->gitpython>=2.1.0->mlflow) (5.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata!=4.7.0,>=3.7.0->mlflow) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.17.3->mlflow) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.17.3->mlflow) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.17.3->mlflow) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.17.3->mlflow) (2.10)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.7/dist-packages (from alembic->mlflow) (1.2.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->mlflow) (5.7.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy->mlflow) (1.1.2)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow) (1.0.1)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow) (2.11.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask->mlflow) (2.0.1)\n",
            "Requirement already satisfied: setuptools>=3.0 in /usr/local/lib/python3.7/dist-packages (from gunicorn->mlflow) (57.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->mlflow) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->mlflow) (2.8.2)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.7/dist-packages (from prometheus-flask-exporter->mlflow) (0.14.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: memoized_property in /usr/local/lib/python3.7/dist-packages (1.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install mlflow\n",
        "!pip install memoized_property\n",
        "import mlflow\n",
        "from mlflow.tracking import MlflowClient\n",
        "from memoized_property import memoized_property"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model set up libraries \n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Activation, ReLU\n",
        "from tensorflow.keras.layers import BatchNormalization, Conv2DTranspose, Concatenate\n",
        "from tensorflow.keras.models import Model, Sequential \n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "metadata": {
        "id": "w6ccFUVADh9T"
      },
      "id": "w6ccFUVADh9T",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data loading libraries \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dq_IxFgvDhnN",
        "outputId": "123023f9-7a80-490b-97d5-9552eb54302b"
      },
      "id": "dq_IxFgvDhnN",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "from PIL import Image\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "T0R15h-dDnPw"
      },
      "id": "T0R15h-dDnPw",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ROOT_PATH = 'drive/MyDrive/SOLAR_ROOF/'\n",
        "FOLDERS = ['tiled_test_images', 'tiled_train_images']\n",
        "FOLDER_PATH = [f'{ROOT_PATH}{folder}/*.tif' for folder in FOLDERS]\n",
        "MLFLOW_URI = \"https://mlflow.lewagon.ai/\"\n",
        "EXPERIMENT_NAME = \"[UK] [LONDON] [SOLAR_ROOF] TEST RUN CLASS\"\n",
        "EXPERIMENT_TAGS = {\n",
        "    'USER': 'CHECK',\n",
        "    'RUN NAME': 'class test',\n",
        "    'VERSION': 'NUMBERS',\n",
        "    'DESCRIPTION': 'testing MLFlow Pipeline using seperate classes and class inheritence. Model - basic U-Net structure, 2 epochs, 15 images'\n",
        "}\n",
        "\n",
        "IMAGE_SIZE = (160,160)\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS = 2"
      ],
      "metadata": {
        "id": "0fmsoLLdO4XC"
      },
      "id": "0fmsoLLdO4XC",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data"
      ],
      "metadata": {
        "id": "1mPzAhaxD21I"
      },
      "id": "1mPzAhaxD21I"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data(num_images=15):\n",
        "    test_path =[filename for filename in glob.glob(FOLDER_PATH[0])]\n",
        "    train_path = [filename for filename in glob.glob(FOLDER_PATH[1])]\n",
        "    \n",
        "    # limit to 15 images for test\n",
        "    test_path.sort()\n",
        "    train_path.sort()\n",
        "    \n",
        "    test_path = test_path[:num_images]\n",
        "    train_path = train_path[:num_images] \n",
        "\n",
        "    X = [] # Image\n",
        "    y = [] # Mask\n",
        "    \n",
        "    images_X = []\n",
        "    images_y = []\n",
        "    \n",
        "    for filename in train_path:\n",
        "      im = Image.open(filename)\n",
        "      # print(filename)\n",
        "      images_X.append(im)\n",
        "      im_resized = im.resize(IMAGE_SIZE)\n",
        "      X.append(image.img_to_array(im_resized))\n",
        "\n",
        "    for filename in test_path:\n",
        "      im = Image.open(filename)\n",
        "      # print(filename)\n",
        "      images_y.append(im)\n",
        "      im_resized = im.resize(IMAGE_SIZE)\n",
        "      y.append(image.img_to_array(im_resized))\n",
        "    \n",
        "    \n",
        "    X = np.array(X) / 255.\n",
        "    y = np.array(y) / 255.\n",
        "    \n",
        "    return X, y"
      ],
      "metadata": {
        "id": "9aTId_PTD4Xo"
      },
      "id": "9aTId_PTD4Xo",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PUSHMLFLOW CLASS"
      ],
      "metadata": {
        "id": "VgFvmyX8DtYM"
      },
      "id": "VgFvmyX8DtYM"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "79102faa",
      "metadata": {
        "id": "79102faa"
      },
      "outputs": [],
      "source": [
        "class PushMLFlow():\n",
        "    # MLFLOW_URI = \"https://mlflow.lewagon.ai/\"\n",
        "    \n",
        "    def __init__(self, experiment_name, experiment_tags):\n",
        "      self.experiment_name = experiment_name\n",
        "      self.experiment_tags = experiment_tags\n",
        "        \n",
        "    @memoized_property\n",
        "    def mlflow_client(self):\n",
        "      mlflow.set_tracking_uri(MLFLOW_URI)\n",
        "      return MlflowClient()\n",
        "\n",
        "    @memoized_property\n",
        "    def mlflow_experiment_id(self):\n",
        "      try:\n",
        "        return self.mlflow_client.create_experiment(self.experiment_name)\n",
        "      except BaseException:\n",
        "        return self.mlflow_client.get_experiment_by_name(self.experiment_name).experiment_id\n",
        "\n",
        "    @memoized_property\n",
        "    def mlflow_run(self):\n",
        "      return self.mlflow_client.create_run(self.mlflow_experiment_id, tags=self.experiment_tags)\n",
        "\n",
        "    def mlflow_log_param(self, key, value):\n",
        "      print('*'*80)\n",
        "      print('LOGGING PARAMS')\n",
        "      self.mlflow_client.log_param(self.mlflow_run.info.run_id, key, value)\n",
        "      print('='*80)\n",
        "      print('LOGGED PARAMS')\n",
        "\n",
        "    def mlflow_log_metric(self, key, value):\n",
        "      self.mlflow_client.log_metric(self.mlflow_run.info.run_id, key, value)\n",
        "          \n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# UNET MODEL CLASS"
      ],
      "metadata": {
        "id": "SYble26qDxQr"
      },
      "id": "SYble26qDxQr"
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelClass(PushMLFlow):\n",
        "    \"\"\"\n",
        "    Class inerhits from PushMLFlow and will push parameters and score when run and evaluate are called.\n",
        "    Inputs: X_train: [NumPy array] - trainning data\n",
        "            X_test: [NumPy array] - test data\n",
        "            y_train: [NumPy array] - trainning data\n",
        "            y_test: [NumPy array] - test data\n",
        "            loss: default='binary_crossentropy'\n",
        "            experiment_name: [str] - saved name of experiemnt \n",
        "            experiment_tags: [Dictionary]{'USER': '', 'RUN NAME': '', 'VERSION':'', 'DESCRIPTION':''} - Fill in relevant meta data\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, X_train, X_test, y_train, y_test,experiment_name, experiment_tags, loss='binary_crossentropy'):\n",
        "        super().__init__(experiment_name, experiment_tags)\n",
        "        self.loss=loss\n",
        "\n",
        "        self.X_train = X_train\n",
        "        self.X_test = X_test\n",
        "        self.y_train = y_train\n",
        "        self.y_test = y_test\n",
        "\n",
        "      \n",
        "    def convolution_operation(self, entered_input, filters=64):  \n",
        "            \n",
        "        # Taking first input and implementing the first conv block\n",
        "        conv1 = Conv2D(filters, kernel_size = (3,3), padding = \"same\")(entered_input)\n",
        "        batch_norm1 = BatchNormalization()(conv1)\n",
        "        act1 = ReLU()(batch_norm1)\n",
        "\n",
        "        # Taking first input and implementing the second conv block\n",
        "        conv2 = Conv2D(filters, kernel_size = (3,3), padding = \"same\")(act1)\n",
        "        batch_norm2 = BatchNormalization()(conv2)\n",
        "        act2 = ReLU()(batch_norm2)\n",
        "\n",
        "        return act2\n",
        "\n",
        "    def encoder(self, entered_input, filters=64):\n",
        "        # Collect the start and end of each sub-block for normal pass and skip connections\n",
        "        enc1 = self.convolution_operation(entered_input, filters)\n",
        "        MaxPool1 = MaxPooling2D(strides = (2,2))(enc1)\n",
        "        return enc1, MaxPool1\n",
        "\n",
        "    def decoder(self, entered_input, skip, filters=64):\n",
        "        # Upsampling and concatenating the essential features\n",
        "        Upsample = Conv2DTranspose(filters, (2, 2), strides=2, padding=\"same\")(entered_input)\n",
        "        Connect_Skip = Concatenate()([Upsample, skip])\n",
        "        out = self.convolution_operation(Connect_Skip, filters)\n",
        "        return out\n",
        "\n",
        "\n",
        "    def U_Net(self, Image_Size):\n",
        "        # Take the image size and shape\n",
        "        input1 = Input(Image_Size)\n",
        "\n",
        "        # Construct the encoder blocks\n",
        "        skip1, encoder_1 = self.encoder(input1, 64)\n",
        "        skip2, encoder_2 = self.encoder(encoder_1, 64*2)\n",
        "        skip3, encoder_3 = self.encoder(encoder_2, 64*4)\n",
        "        skip4, encoder_4 = self.encoder(encoder_3, 64*8)\n",
        "\n",
        "        # Preparing the next block\n",
        "        conv_block = self.convolution_operation(encoder_4, 64*16)\n",
        "\n",
        "        # Construct the decoder blocks\n",
        "        decoder_1 = self.decoder(conv_block, skip4, 64*8)\n",
        "        decoder_2 = self.decoder(decoder_1, skip3, 64*4)\n",
        "        decoder_3 = self.decoder(decoder_2, skip2, 64*2)\n",
        "        decoder_4 = self.decoder(decoder_3, skip1, 64)\n",
        "\n",
        "        out = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(decoder_4)\n",
        "\n",
        "        model = Model(input1, out)\n",
        "        return model\n",
        "\n",
        "    def set_model(self):\n",
        "        \n",
        "        # Instantiate Model\n",
        "        input_shape = self.X_train.shape[1:]\n",
        "        self.model = self.U_Net(input_shape)\n",
        "\n",
        "        # Compile Model\n",
        "        self.model.compile(loss=self.loss, \n",
        "                    optimizer='adam')\n",
        "\n",
        "    def run(self):\n",
        "\n",
        "        print(80*'-')\n",
        "        print('------MODEL RUNNING------')\n",
        "\n",
        "        # set model\n",
        "        self.set_model()\n",
        "\n",
        "        mc = ModelCheckpoint('oxford_segmentation.h5', save_best_only=True) # could put path here \n",
        "\n",
        "        self.model.fit(self.X_train, self.y_train, validation_split=0.3,\n",
        "                  batch_size=BATCH_SIZE, epochs=EPOCHS, callbacks=[mc])\n",
        "\n",
        "        self.mlflow_log_param('loss', self.loss)\n",
        "\n",
        "        print(80*'=')\n",
        "        print('------MODEL SUCCESFULLY------')\n",
        "\n",
        "\n",
        "    def evaluate(self):\n",
        "        print(80*'-')\n",
        "        print('------MODEL EVALUATING------')        \n",
        "        results = self.model.evaluate(self.X_test, self.y_test)\n",
        "        self.mlflow_log_metric('loss', results)\n",
        "        print(80*'=')\n",
        "        print('------MODEL EVALUATED------')\n"
      ],
      "metadata": {
        "id": "9a7cAAK8DwXV"
      },
      "id": "9a7cAAK8DwXV",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing Code"
      ],
      "metadata": {
        "id": "5-vBz0cGD-qs"
      },
      "id": "5-vBz0cGD-qs"
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9aTcVEQRFTzZ"
      },
      "id": "9aTcVEQRFTzZ",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = get_data()\n"
      ],
      "metadata": {
        "id": "80dEsGrcD_Y5"
      },
      "id": "80dEsGrcD_Y5",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
      ],
      "metadata": {
        "id": "JfDxPFlVFuDY"
      },
      "id": "JfDxPFlVFuDY",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# instantiate model \n",
        "model = ModelClass(X_train, X_test, y_train, y_test, EXPERIMENT_NAME, EXPERIMENT_TAGS)\n"
      ],
      "metadata": {
        "id": "_QN6FG12FuBA"
      },
      "id": "_QN6FG12FuBA",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4D9vs-QFt-r",
        "outputId": "ca26e29d-678e-4d47-e842-3e2d2835bf4f"
      },
      "id": "b4D9vs-QFt-r",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "------MODEL RUNNING------\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 30s 30s/step - loss: 0.8469 - val_loss: 0.7514\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.7715 - val_loss: 0.7638\n",
            "********************************************************************************\n",
            "LOGGING PARAMS\n",
            "================================================================================\n",
            "LOGGED PARAMS\n",
            "================================================================================\n",
            "------MODEL SUCCESFULLY------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nYoAw0TLqVN",
        "outputId": "b02001eb-4c65-4184-d687-50a03f96a8e7"
      },
      "id": "9nYoAw0TLqVN",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "------MODEL EVALUATING------\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.7512\n",
            "================================================================================\n",
            "------MODEL EVALUATED------\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "class_full_mlflow_model_push_test.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}